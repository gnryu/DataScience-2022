{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modeling_evaluation_func.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNVuTVdGKV+Ya+m6uWpmKqG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnryu/DataScience_TermProject/blob/main/modeling_evaluation_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression"
      ],
      "metadata": {
        "id": "PL0QpuDWKr-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LogisticRegressionFunc(df):\n",
        "  # select\n",
        "  X = df.iloc[:, :-1].values\n",
        "  y = df['Severity'].values\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 45)\n",
        "  \n",
        "  # logistic Regression\n",
        "  model = LogisticRegression(random_state = 77)\n",
        "\n",
        "  model.fit(X_train, y_train)\n",
        "  y_predict = model.predict(X_test)\n",
        "  acc = accuracy_score(y_test, y_predict)\n",
        "\n",
        "  print(\"Logistic regression accuracy_score: {}.\".format(acc))\n",
        "\n",
        "  # confusion Matrix\n",
        "  confusionMatrix = confusion_matrix(y_true = y_test, y_pred = y_predict)\n",
        "\n",
        "  # visualization\n",
        "  index = [\"Actual Severity 1\", \"Actual Severity 2\", \"Actual Severity 3\", \"Actual Severity 4\"]\n",
        "  columns = [\"Predicted Severity 1\", \"Predicted Severity 2\", \"Predicted Severity 3\", \"Predicted Severity 4\"]\n",
        "  conf_matrix = pd.DataFrame(data=confusionMatrix, columns=columns, index=index)\n",
        "  plt.figure(figsize=(8, 5))\n",
        "  sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"YlGnBu\")\n",
        "  plt.title(\"Confusion Matrix - Logistic Regression\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "mZgg4QkuKqnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN"
      ],
      "metadata": {
        "id": "85oKDT7hKfOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QnETmG5hKGGG"
      },
      "outputs": [],
      "source": [
        "def KNN(data, target, scale_encode_method):\n",
        "  # create a dataframe with all training data except the target feature\n",
        "  X = data.drop(columns = [target])\n",
        "\n",
        "  X = scale_encode_method(X) # scale the data\n",
        "  y = data[target].values # seperate target feature\n",
        "\n",
        "  # split dataset into train and test data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)\n",
        "\n",
        "  # create new knn model\n",
        "  knn = KNeighborsClassifier()\n",
        "\n",
        "  # create a dictionary of all values we want to test for n_neighbors\n",
        "  param_grid = {'n_neighbors': np.arange(1, 25)}\n",
        "\n",
        "  # use GridSearch to test all values for n_neighbors\n",
        "  knn_gscv = GridSearchCV(knn, param_grid, cv = 5)\n",
        "\n",
        "  # fit model to data\n",
        "  knn_gscv.fit(X_train, y_train)\n",
        "\n",
        "  # check top performing n_neighbors value\n",
        "  # print(knn_gscv.best_params_)\n",
        "\n",
        "  # check the mean score for the top performing value of n_neighbors\n",
        "  # print(knn_gscv.best_score_)\n",
        "\n",
        "  knn2 = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_.get('n_neighbors'))\n",
        "  knn2.fit(X_train, y_train)\n",
        "  # print(knn2.score(X_test, y_test))\n",
        "\n",
        "  return knn_gscv.best_params_, knn2.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def KNN_eval(data, target, scale_encode_method, knn_best_k):\n",
        "  # create a dataframe with all training data except the target feature\n",
        "  X = data.drop(columns = [target])\n",
        "\n",
        "  X = scale_encode_method(X) # scale the data\n",
        "  y = data[target].values # seperate target feature\n",
        "\n",
        "  knn_cv = KNeighborsClassifier(n_neighbors = knn_best_k.get('n_neighbors'))\n",
        "  cv_scores = cross_val_score(knn_cv, X, y, cv = 5)\n",
        "\n",
        "  # print(cv_scores)\n",
        "  # print('cv_scores mean: {}'.format(np.mean(cv_scores)))\n",
        "  return cv_scores"
      ],
      "metadata": {
        "id": "oPy17twGKoKH"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SVM"
      ],
      "metadata": {
        "id": "Kx7cBTuCK7Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def svm(data):\n",
        "    #X = data.iloc[:, :-1].values\n",
        "    dp=pd.DataFrame.copy(data)\n",
        "    X = dp.iloc[:, :-1].values\n",
        "    y = data_Orlando_test['Severity'].values\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,stratify=y,random_state=1)\n",
        "    svm_clf =svm.SVC(kernel = 'linear')\n",
        "    svm_clf.fit(X_train,y_train)\n",
        "    y_predict=svm_clf.predict(X_test)\n",
        "\n",
        "    #grid search\n",
        "    param_grid = {'C': [0.1, 1, 10, 100]}\n",
        "    clf_grid = GridSearchCV(svm.SVC(), param_grid, verbose=1)\n",
        "    clf_grid.fit(X_train,y_train)\n",
        "    print(\"Best Parameters:\\n\", clf_grid.best_params_)\n",
        "\n",
        "    #find score\n",
        "    scores = cross_val_score(svm_clf, X, y, cv =3 )\n",
        "    return scores"
      ],
      "metadata": {
        "id": "gWqc0vJpK7fc"
      },
      "execution_count": 3,
      "outputs": []
    }
  ]
}