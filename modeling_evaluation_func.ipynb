{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "modeling_evaluation_func.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM7xybE+iX3h7KGaf/hmPY0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gnryu/DataScience_TermProject/blob/main/modeling_evaluation_func.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Linear Regression**"
      ],
      "metadata": {
        "id": "_yugR2VVtUlu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input: whole dataset, X value, y value\n",
        "def Linear_Regression(df, X, y):\n",
        "  from sklearn.linear_model import LinearRegression\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  import matplotlib.pyplot as plt\n",
        "\n",
        "  X = df[X].values.reshape(-1,1)\n",
        "  y = df[y].values\n",
        "\n",
        "  # Split data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 10)\n",
        "\n",
        "  #create model & train model\n",
        "  model = LinearRegression()\n",
        "  model.fit(X_train, y_train)\n",
        "  y_predict = model.predict(X_test)\n",
        "\n",
        "  # scorer\n",
        "  score = model.score(X_test, y_test)\n",
        "\n",
        "  # print & draw\n",
        "  print(\"Socre: \" + str(score))\n",
        "  print(\"coef_ : \" + str(model.coef_))\n",
        "  print(\"intercept_ : \" + str(model.intercept_))\n",
        "\n",
        "  plt.plot(X_test, y_predict)\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Zbn-EjUItbTl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **KNN**"
      ],
      "metadata": {
        "id": "85oKDT7hKfOw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QnETmG5hKGGG"
      },
      "outputs": [],
      "source": [
        "# modeling\n",
        "# input: whole dataset, target feature, scaling/encoding method\n",
        "# return: best accurate k, test set performance of KNN model of that k\n",
        "def KNN(data, target, scale_encode_method):\n",
        "  from sklearn.model_selection import train_test_split\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "  # create a dataframe with all training data except the target feature\n",
        "  X = data.drop(columns = [target])\n",
        "\n",
        "  X = scale_encode_method(X) # scale the data\n",
        "  y = data[target].values # seperate target feature\n",
        "\n",
        "  # split dataset into train and test data\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1, stratify = y)\n",
        "\n",
        "  # create new knn model\n",
        "  knn = KNeighborsClassifier()\n",
        "\n",
        "  # create a dictionary of all values we want to test for n_neighbors\n",
        "  param_grid = {'n_neighbors': np.arange(1, 25)}\n",
        "\n",
        "  # use GridSearch to test all values for n_neighbors\n",
        "  knn_gscv = GridSearchCV(knn, param_grid, cv = 5)\n",
        "\n",
        "  # fit model to data\n",
        "  knn_gscv.fit(X_train, y_train)\n",
        "\n",
        "  # check top performing n_neighbors value\n",
        "  # print(knn_gscv.best_params_)\n",
        "\n",
        "  # check the mean score for the top performing value of n_neighbors\n",
        "  # print(knn_gscv.best_score_)\n",
        "\n",
        "  knn2 = KNeighborsClassifier(n_neighbors = knn_gscv.best_params_.get('n_neighbors'))\n",
        "  knn2.fit(X_train, y_train)\n",
        "  # print(knn2.score(X_test, y_test))\n",
        "\n",
        "  return knn_gscv.best_params_, knn2.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate\n",
        "# input: whole dataset, target feature, scaling/encoding method, k obtained through KNN()\n",
        "# return: performance in each bundle of k-fold cross validation\n",
        "def KNN_eval(data, target, scale_encode_method, knn_best_k):\n",
        "  from sklearn.neighbors import KNeighborsClassifier\n",
        "  from sklearn.model_selection import cross_val_score\n",
        "  # create a dataframe with all training data except the target feature\n",
        "  X = data.drop(columns = [target])\n",
        "\n",
        "  X = scale_encode_method(X) # scale the data\n",
        "  y = data[target].values # seperate target feature\n",
        "\n",
        "  knn_cv = KNeighborsClassifier(n_neighbors = knn_best_k.get('n_neighbors'))\n",
        "  cv_scores = cross_val_score(knn_cv, X, y, cv = 5)\n",
        "\n",
        "  # print(cv_scores)\n",
        "  # print('cv_scores mean: {}'.format(np.mean(cv_scores)))\n",
        "  return cv_scores"
      ],
      "metadata": {
        "id": "oPy17twGKoKH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Decision Tree Classifier**"
      ],
      "metadata": {
        "id": "Kx7cBTuCK7Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# input: whole dataset\n",
        "# return: decision tree's test score and train score\n",
        "def decision_tree(data):\n",
        "    import pandas as pd\n",
        "    from sklearn.tree import DecisionTreeClassifier\n",
        "    from sklearn.model_selection import train_test_split\n",
        "    from sklearn import tree\n",
        "\n",
        "    dp=pd.DataFrame.copy(data)\n",
        "    #data\n",
        "    X = dp.iloc[:, 1:].values\n",
        "    #target\n",
        "    y = data['Severity'].values\n",
        "\n",
        "    #split data train,test\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3,stratify=y,random_state=1)\n",
        "    #use decisiontree\n",
        "    tree_model = DecisionTreeClassifier()\n",
        "    #fit to model\n",
        "    tree_model.fit(X_train,y_train)\n",
        "    #check score\n",
        "    print(\"Train Set Score:{:.2f}\".format(tree_model.score(X_train,y_train)))\n",
        "    print(\"test Set Score:{:.2f}\".format(tree_model.score(X_test,y_test)))"
      ],
      "metadata": {
        "id": "cbRxMmfdvKKY"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}